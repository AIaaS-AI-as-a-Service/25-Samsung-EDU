{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. 변형 회귀 (Variant Regression)**\n",
    ": 선형 회귀가 갖는 다양한 한계를 보완하기 위해 확장된 회귀 모델들\n",
    "\n",
    "선형 회귀(OLS) 가정\n",
    "- 선형성(linearity)\n",
    "- 정규성(normality)\n",
    "- 등분산성(homoscedasticity)\n",
    "- 독립성(independence)\n",
    "\n",
    "하지만 실제 데이터는 이러한 가정을 자주 위반 \\\n",
    "변수 개수가 많거나 비선형 패턴 존재  \n",
    "이를 해결하기 위해 여러 변형 회귀 기법(Variant Regression)을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **필요한 라이브러리 가져오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, QuantileRegressor, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"font.size\"] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/california_housing.csv')\n",
    "\n",
    "print(\"\\n데이터 셋의 일부를 확인해보면 아래와 같습니다.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<b><font size=4>* 변수에 대한 설명</font></b><br><br>\n",
    "\n",
    "- MedInc : 지역의 중위소득 (Median Income)<br>\n",
    "- HouseAge : 주택의 평균 연식 (Average House Age)<br>\n",
    "- AveRooms : 가구당 평균 방(room) 수<br>\n",
    "- AveBedrms : 가구당 평균 침실 수<br>\n",
    "- Population : 지역 인구수<br>\n",
    "- AveOccup : 가구당 평균 거주자 수<br>\n",
    "- Latitude : 위도<br>\n",
    "- Longitude : 경도<br>\n",
    "- MedHouseVal : 지역의 중위 주택가격 (Target, 단위: 10만 달러)<br>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 전처리**\n",
    "- 데이터 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- describe() 함수를 사용해서 수치형 변수들만을 기준으로 카운트, 평균, 표준편차, 최소/최댓값, 4분위 수를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 시각화**\n",
    "- 변수 간 상관 관계 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 특성의 분포에 대한 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=15, figsize=(15, 10), layout=(4, 3))\n",
    "plt.suptitle('Feature Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 분리**\n",
    "- 데이터를 학습 데이터 세트와 테스트 데이터 세트로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립 변수(X)와 종속 변수(y)를 정의\n",
    "X = df.drop(\"MedHouseVal\", axis=1)\n",
    "y = df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 80%는 학습에 사용되고 20%는 테스트에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"\\n학습 세트 크기:\", X_train.shape[0])\n",
    "print(\"테스트 세트 크기:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 스케일링 후 DataFrame으로 복원\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled  = pd.DataFrame(X_test_scaled,  columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression**\n",
    "- LinearRegression 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터에 대한 가격 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n모델 계수(기울기):\", lr_model.coef_[0])\n",
    "print(\"모델 절편(y절편):\", lr_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAE, MSE, R2 값을 비교하여 모델을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_housing = mean_absolute_error(y_test,y_pred)\n",
    "mse_housing = mean_squared_error(y_test,y_pred)\n",
    "r2_housing = r2_score(y_test,y_pred)\n",
    "\n",
    "print(\"\\n[모델 평가 지표]\")\n",
    "print(\"\\n- 평균 절대 오차 (MAE):\", mae_housing)\n",
    "print(\"- 평균 제곱 오차 (MSE):\", mse_housing)\n",
    "print(\"- R-제곱 (R2) 값:\", r2_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7-1 Stepwise Regression**\n",
    "\n",
    "\n",
    "- 불필요한 변수를 제거하고 중요한 변수만 선택하는 회귀 방식\n",
    "- **Forward Selection**: 유의한 변수를 하나씩 추가  \n",
    "- **Backward Elimination**: 덜 유의한 변수를 하나씩 제거  \n",
    "- **Bidirectional**: 두 방법을 동시에 적용하여 균형 잡힌 선택 수행  \n",
    "- 기준: **교차검증(CV) RMSE** \n",
    "- 목적: **불필요한 변수를 줄이고, 해석 가능한 간결한 모델** 확보  \n",
    "- 장점:  \n",
    "  - 많은 후보 변수 중 핵심 변수 자동 선택  \n",
    "  - 모델 복잡도 감소  \n",
    "- 단점:  \n",
    "  - 탐욕적(greedy) → 전역 최적 보장 안 됨  \n",
    "  - 다중공선성(multicollinearity)에 취약  \n",
    "  - 변수 선택 과정에서 과적합 위험 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7-1-1. 전진선택법 (Forward Selection)**\n",
    "\n",
    "- **Forward Selection**: 유의한 변수를 하나씩 추가  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 가정: forward_selection 함수에서 성능(metric)과 선택된 변수를 반환하도록 수정\n",
    "def forward_selection_with_visualization(X, y, significance_level=0.05):\n",
    "    initial_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    selected_features = []\n",
    "    model_performance = []  # 모델 성능 추적 (예: R^2 또는 AIC)\n",
    "\n",
    "    while remaining_features:\n",
    "        best_pval = float(\"inf\")\n",
    "        best_feature = None\n",
    "        for feature in remaining_features:\n",
    "            X_subset = sm.add_constant(X[initial_features + [feature]])\n",
    "            model = sm.OLS(y, X_subset).fit()\n",
    "            pval = model.pvalues[feature]\n",
    "            if pval < best_pval and pval < significance_level:\n",
    "                best_pval = pval\n",
    "                best_feature = feature\n",
    "        if best_feature:\n",
    "            initial_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            selected_features.append(best_feature)\n",
    "            # 모델 성능 저장\n",
    "            X_subset = sm.add_constant(X[initial_features])\n",
    "            model = sm.OLS(y, X_subset).fit()\n",
    "            model_performance.append(model.rsquared)  # R^2 값 저장\n",
    "        else:\n",
    "            break\n",
    "    return selected_features, model_performance\n",
    "\n",
    "selected_features, model_performance = forward_selection_with_visualization(X, y)\n",
    "\n",
    "print(\"전진 선택법 이후 선택된 변수들 :\", selected_features)\n",
    "print(\"전진 선택에 따른 모델 성능:\", model_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(model_performance) + 1), model_performance, marker='o', linestyle='-')\n",
    "plt.xticks(range(1, len(model_performance) + 1), selected_features, rotation=45)\n",
    "plt.xlabel('Selected Features (in order)')\n",
    "plt.ylabel('Model Performance (R^2)')\n",
    "plt.title('Forward Selection: Feature Addition and Model Performance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7-1-2. 후진제거법 (Backward Elimination)**\n",
    "\n",
    "- **Backward Elimination**: 덜 유의한 변수를 하나씩 제거  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 후진 소거법 구현\n",
    "def backward_elimination_with_visualization(X, y, significance_level=0.05):\n",
    "    features = list(X.columns)  # 모든 독립 변수 포함\n",
    "    model_performance = []  # 모델 성능 기록 (R^2)\n",
    "\n",
    "    while len(features) > 0:\n",
    "        # 현재 변수로 회귀 모델 생성\n",
    "        X_subset = sm.add_constant(X[features])  # 상수항 추가\n",
    "        model = sm.OLS(y, X_subset).fit()\n",
    "\n",
    "        # R^2 기록\n",
    "        model_performance.append(model.rsquared)\n",
    "\n",
    "        # p-value가 가장 높은 변수 찾기\n",
    "        pvalues = model.pvalues[1:]  # 상수(constant)는 제외\n",
    "        max_pval = pvalues.max()\n",
    "\n",
    "        if max_pval > significance_level:  # 유의수준 초과 시 변수 제거\n",
    "            excluded_feature = pvalues.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break  # 모든 변수의 p-value가 유의수준 이하일 경우 종료\n",
    "\n",
    "    return features, model_performance\n",
    "\n",
    "selected_features_backward, model_performance_backward = backward_elimination_with_visualization(X, y)\n",
    "\n",
    "print(\"후진 제거법 이후 선택된 변수들 :\", selected_features_backward)\n",
    "print(\"후진 제거에 따른 모델 성능:\", model_performance_backward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "x_ticks = range(len(model_performance_backward))\n",
    "\n",
    "# 모델 성능 그래프\n",
    "plt.plot(x_ticks, model_performance_backward, marker='o', linestyle='-', color='b', label='R^2')\n",
    "\n",
    "# x축 레이블 (남아있는 변수 이름) 길이 조정\n",
    "adjusted_features = selected_features_backward[::-1][:len(model_performance_backward)]\n",
    "plt.xticks(x_ticks, adjusted_features, rotation=45)\n",
    "\n",
    "plt.xlabel('Remaining Features (in order of removal)')\n",
    "plt.ylabel('Model Performance (R^2)')\n",
    "plt.title('Backward Elimination: Feature Removal and Model Performance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7-1-3. Bidirectional**\n",
    "\n",
    "- **Bidirectional**: 두 방법을 동시에 적용하여 균형 잡힌 선택 수행  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bidirectional_stepwise_with_visualization(X, y, significance_level_in=0.05, significance_level_out=0.05):\n",
    "    selected_features = []              # 현재 선택된 변수 집합\n",
    "    remaining_features = list(X.columns)  # 선택되지 않은 변수들\n",
    "    model_performance = []              # 각 단계에서의 모델 성능 기록 (R²)\n",
    "\n",
    "    while True:\n",
    "        changed = False\n",
    "\n",
    "        # -----------------------------\n",
    "        # 1) Forward Selection Step\n",
    "        # -----------------------------\n",
    "        best_pval = float(\"inf\")\n",
    "        best_feature = None\n",
    "\n",
    "        for feature in remaining_features:\n",
    "            X_subset = sm.add_constant(X[selected_features + [feature]])\n",
    "            model = sm.OLS(y, X_subset).fit()\n",
    "\n",
    "            pval = model.pvalues[feature]\n",
    "\n",
    "            if pval < best_pval and pval < significance_level_in:\n",
    "                best_pval = pval\n",
    "                best_feature = feature\n",
    "\n",
    "        if best_feature is not None:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            changed = True\n",
    "\n",
    "            # 모델 성능 저장\n",
    "            X_subset = sm.add_constant(X[selected_features])\n",
    "            model = sm.OLS(y, X_subset).fit()\n",
    "            model_performance.append(model.rsquared)\n",
    "\n",
    "        # -----------------------------\n",
    "        # 2) Backward Elimination Step\n",
    "        # -----------------------------\n",
    "        if len(selected_features) > 0:\n",
    "            X_subset = sm.add_constant(X[selected_features])\n",
    "            model = sm.OLS(y, X_subset).fit()\n",
    "\n",
    "            # 상수항 제외\n",
    "            pvalues = model.pvalues.iloc[1:]\n",
    "\n",
    "            worst_pval = pvalues.max()\n",
    "            worst_feature = pvalues.idxmax()\n",
    "\n",
    "            if worst_pval > significance_level_out:\n",
    "                selected_features.remove(worst_feature)\n",
    "                remaining_features.append(worst_feature)\n",
    "                changed = True\n",
    "\n",
    "                # 모델 성능 저장\n",
    "                X_subset = sm.add_constant(X[selected_features]) if selected_features else None\n",
    "                if selected_features:\n",
    "                    model = sm.OLS(y, X_subset).fit()\n",
    "                    model_performance.append(model.rsquared)\n",
    "                else:\n",
    "                    model_performance.append(None)\n",
    "\n",
    "        # -----------------------------\n",
    "        # 종료 조건\n",
    "        # -----------------------------\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return selected_features, model_performance\n",
    "\n",
    "# 함수 실행\n",
    "selected_features_bidir, performance_bidir = bidirectional_stepwise_with_visualization(X, y)\n",
    "\n",
    "print(\"Bidirectional Stepwise 이후 선택된 변수들 :\", selected_features_bidir)\n",
    "print(\"Bidirectional Stepwise 성능 변화:\", performance_bidir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(performance_bidir) + 1), performance_bidir,\n",
    "         marker='o', linestyle='-', color='green')\n",
    "plt.xticks(range(1, len(performance_bidir) + 1), selected_features_bidir + ([\"\"] * (len(performance_bidir) - len(selected_features_bidir))), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Feature Added/Removed (Step Order)\")\n",
    "plt.ylabel(\"Model Performance (R²)\")\n",
    "plt.title(\"Bidirectional Stepwise: Feature Selection and Model Performance\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7-2. Quantile Regression**\n",
    "\n",
    "\\begin{equation}\n",
    "Q_\\tau(Y|X) = \\beta_{\\tau,0} + \\beta_{\\tau,1} x_1 + \\cdots + \\beta_{\\tau,p} x_p\n",
    "\\end{equation}\n",
    "\n",
    "- 평균이 아니라 **조건부 분위수(quantile)**를 예측하는 회귀\n",
    "- 평균(OLS)만 설명하는 대신, **분포의 여러 지점(예: 0.1, 0.5, 0.9 분위)** 을 직접 추정  \n",
    "- **Pinball(Quantile) Loss** 최소화를 통해 학습  \n",
    "- 장점:  \n",
    "  - **비대칭 분포**나 **꼬리(heavy tail)** 특성을 반영 가능  \n",
    "  - **이상치(outlier)에 강건** (특히 median regression, q=0.5)  \n",
    "  - 중앙값, 하위/상위 분위 등 **다양한 조건부 경향** 분석 가능  \n",
    "- 단점:  \n",
    "  - 평균 기준 지표(MSE, R²)에서는 OLS보다 불리하게 보일 수 있음  \n",
    "  - 분위 간 **교차(crossing)** 문제 발생 가능  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 3) Quantile Regression (MedInc만 사용)\n",
    "# --------------------\n",
    "feature = \"MedInc\"\n",
    "\n",
    "X_train_medinc = X_train_scaled[[feature]]\n",
    "X_test_medinc  = X_test_scaled[[feature]]\n",
    "\n",
    "# x축 범위 (원본 값)\n",
    "x_min = X[feature].min()\n",
    "x_max = X[feature].max()\n",
    "x_range_original = np.linspace(x_min, x_max, 200).reshape(-1, 1)\n",
    "\n",
    "# x_range_original -> scaled 변환\n",
    "x_range_scaled = scaler.transform(\n",
    "    pd.DataFrame(np.hstack([x_range_original,\n",
    "                            np.zeros((200, X_train.shape[1]-1))]),\n",
    "                 columns=X.columns)\n",
    ")\n",
    "x_range_scaled_medinc = x_range_scaled[:, X.columns.get_loc(feature)].reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X[feature], y, alpha=0.2)\n",
    "\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "\n",
    "for q in quantiles:\n",
    "    model_q = QuantileRegressor(quantile=q, alpha=0.001)\n",
    "    model_q.fit(X_train_medinc, y_train)\n",
    "\n",
    "    y_q_pred = model_q.predict(x_range_scaled_medinc)\n",
    "    plt.plot(x_range_original, y_q_pred, label=f\"tau={q}\")\n",
    "\n",
    "plt.xlabel(\"MedInc\")\n",
    "plt.ylabel(\"MedHouseVal\")\n",
    "plt.title(\"Quantile Regression (MedInc → MedHouseVal)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7-3. Bayesian Regression**\n",
    "\n",
    "- 회귀 계수를 **점추정**이 아닌 **확률분포**로 추정하는 모델\n",
    "- **불확실성까지 예측** : 예측값뿐 아니라 표준편차/예측구간(PI) 제공\n",
    "- **사전(prior)으로 수축** : 작은 표본·다중공선성에서 과적합 완화\n",
    "- **ARD (Automatic Relevance Determination)** : 불필요한 변수의 계수를 자동으로 0 근처로 수축\n",
    "- 장점:\n",
    "    - 작은 n / 큰 p, 강한 다중공선성에서도 안정적인 추정 가능\n",
    "    - 계수·예측의 불확실성을 함께 제공\n",
    "- 단점:\n",
    "    - 가우시안/등분산 가정에 기반하여 이상치·비대칭 분포·이분산에 취약\n",
    "    - 사전(prior) 의존성으로 인한 편향 가능\n",
    "    - 하이퍼파라미터·evidence 해석이 직관적이지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "model_bayes = BayesianRidge()\n",
    "model_bayes.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측 + 불확실성\n",
    "y_mean, y_std = model_bayes.predict(X_test_scaled, return_std=True)\n",
    "\n",
    "print(\"Bayesian Regression\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_mean)))\n",
    "print(\"R^2 :\", r2_score(y_test, y_mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "order = np.argsort(y_mean)\n",
    "\n",
    "plt.errorbar(\n",
    "    np.arange(len(y_mean))[order],\n",
    "    y_mean[order],\n",
    "    yerr=y_std[order],\n",
    "    fmt=\"o\",\n",
    "    alpha=0.5\n",
    ")\n",
    "plt.title(\"Bayesian Regression Prediction Uncertainty\")\n",
    "plt.xlabel(\"Sorted Test Samples\")\n",
    "plt.ylabel(\"Predicted MedHouseVal\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7-4. Generalized Linear Model (GLM)**\n",
    "\n",
    "\\begin{equation}\n",
    "g(\\mu) = X\\beta\n",
    "\\end{equation}\n",
    "\n",
    "- 종속변수가 정규분포가 아닐 때 사용하는 일반화된 회귀 프레임워크\n",
    "- 다양한 분포(이항, 포아송 등) 지원  \n",
    "- 링크 함수(link function)를 통해 분포와 선형식 연결\n",
    "- **장점**\n",
    "    - 카운트/율 데이터에 자연스러운 손실(편차)와 해석(계수 -> 비율 변화) 제공\n",
    "    - 오프셋(log 노출 시간) 등 실무 확장 용이\n",
    "\n",
    "- **단점**\n",
    "    - 과산포(Var > μ), 제로-인플레이션이 크면 부적합 -> NB/Quasi/ZIP 고려\n",
    "    - 링크 공간 비선형·상호작용 누락 시 편향, 반복측정 상관 시 GLMM/GEE 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula_glm = \"MedHouseVal ~ MedInc + AveRooms + AveOccup\"\n",
    "\n",
    "model_glm = smf.glm(\n",
    "    formula=formula_glm,\n",
    "    data=df,\n",
    "    family=sm.families.Poisson()\n",
    ").fit()\n",
    "\n",
    "print(model_glm.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7-5. Spline Regression**\n",
    "\n",
    "- 하나의 직선이 아닌, **구간별(piecewise)** 다항함수로 비선형 관계 모델링\n",
    "- 전체 구간에서 하나의 다항식(예: 다항 회귀)을 쓰는 대신, 특정 지점(**knots**)을 기준으로 구간을 나누어 각 구간마다 다항식을 적합\n",
    "- 구간이 바뀌더라도 함수값과 기울기(미분값)가 매끄럽게 이어지도록 **연속성(continuity)** 조건을 부여\n",
    "- Cubic Spline(3차 스플라인)이 가장 일반적으로 사용\n",
    "- 장점:  \n",
    "  - 비선형 패턴을 효과적으로 설명할 수 있음\n",
    "  - 고차 다항식 회귀보다 안정적이고 과적합 위험이 적음\n",
    "  - 국소적으로 유연하여 다양한 데이터 형태를 잘 포착\n",
    "\n",
    "\n",
    "- 단점:\n",
    "  - Knot의 위치와 개수를 임의로 정해야 하는 경우 다수 → 모델 선택 어려움\n",
    "  - 구간이 많아질수록 모델이 복잡해지고 해석력 저해\n",
    "  - Knot 위치를 잘못 선택하면 성능이 크게 저하"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "x_s = df[\"MedInc\"]\n",
    "y_s = df[\"MedHouseVal\"]\n",
    "\n",
    "# Spline basis 생성\n",
    "transformed_x = dmatrix(\n",
    "    \"bs(x_s, df=6, degree=3)\",\n",
    "    {\"x_s\": x_s},\n",
    "    return_type=\"dataframe\"\n",
    ")\n",
    "\n",
    "# OLS 적합\n",
    "model_spline = sm.OLS(y_s, transformed_x).fit()\n",
    "\n",
    "# 예측 범위\n",
    "x_range = np.linspace(x_s.min(), x_s.max(), 300)\n",
    "x_range_bs = dmatrix(\n",
    "    \"bs(x_range, df=6, degree=3)\",\n",
    "    {\"x_range\": x_range},\n",
    "    return_type=\"dataframe\"\n",
    ")\n",
    "y_pred = model_spline.predict(x_range_bs)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x_s, y_s, alpha=0.3)\n",
    "plt.plot(x_range, y_pred, color=\"red\")\n",
    "plt.title(\"Spline Regression (MedInc → MedHouseVal)\")\n",
    "plt.xlabel(\"MedInc\")\n",
    "plt.ylabel(\"MedHouseVal\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7-6. Locally Weighted Regression (LWR / LOESS)**\n",
    "\n",
    "- Weighted Regression(가중 회귀)은 각 데이터 포인트에 가중치(weight)를 부여하여 모델을 학습하는 방법  \n",
    "- 모든 데이터가 동일한 중요도를 가진다고 가정하는 일반 회귀와 달리, 특정 구간이나 특정 데이터의 영향력을 줄이거나 높일 수 있음\n",
    "- 데이터가 이질적이거나, 관측값의 신뢰도가 다를 때 효과적\n",
    "\n",
    "- 장점\n",
    "  - **이상치(outlier) 완화**: 이상치나 신뢰도 낮은 데이터의 가중치를 줄여 모델에 미치는 영향을 최소화할 수 있음  \n",
    "  - **데이터 품질 반영**: 관측값의 정확도, 표본 추출 과정의 신뢰도 등에 따라 데이터를 차등 반영 가능  \n",
    "  - **유연한 모델링**: 특정 구간의 패턴을 더 강조하거나, 특정 집단의 데이터에 집중할 수 있음  \n",
    "  - **현실적 적용**: 실험 데이터, 설문 데이터처럼 각 관측치의 신뢰도가 다를 때 매우 유용\n",
    "\n",
    "\n",
    "- 단점\n",
    "  - **가중치 설정의 어려움**: 가중치를 어떻게 줄지 명확한 기준이 없으면 오히려 왜곡된 결과를 만들 수 있음  \n",
    "  - **해석 복잡성**: 단순 OLS보다 결과 해석이 어렵고, 잘못된 가중치 부여는 편향(bias)을 심화시킬 수 있음  \n",
    "  - **데이터 의존성**: 특정 구간의 데이터가 너무 적거나 가중치가 지나치게 낮으면 해당 구간은 거의 무시됨  \n",
    "  - **계산 복잡성 증가**: 대규모 데이터에서 WLS(Weighted Least Squares) 적용 시 계산량이 늘어날 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lw = df[[\"MedInc\"]]\n",
    "y_lw = df[\"MedHouseVal\"]\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=20, weights=\"distance\")\n",
    "knn.fit(X_lw, y_lw)\n",
    "\n",
    "x_grid = np.linspace(X_lw.min(), X_lw.max(), 200).reshape(-1, 1)\n",
    "y_grid = knn.predict(x_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_lw, y_lw, alpha=0.2)\n",
    "plt.plot(x_grid, y_grid, color=\"red\")\n",
    "plt.title(\"Locally Weighted Regression (MedInc → MedHouseVal)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reg_jupyter",
   "language": "python",
   "name": "reg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
