# Samsung Education Day-8: Machine Learning Classification

## ğŸ“š ê³¼ì • ê°œìš”

ì´ ê³¼ì •ì€ 4ê°€ì§€ ì£¼ìš” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì„ **ì‹¤ë¬´ ë°ì´í„°**ì™€ **êµìœ¡ìš© ë°ì´í„°**ë¥¼ í˜¼í•©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.

**ì†Œìš” ì‹œê°„**: 3-4ì‹œê°„  
**ë‚œì´ë„**: ì¤‘ê¸‰  
**ì‚¬ì „ ì§€ì‹**: Python ê¸°ì´ˆ, NumPy, Pandas ê¸°ì´ˆ

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
new_day-8/
â”œâ”€â”€ data/                       # ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ secom.data             # SECOM ì„¼ì„œ ë°ì´í„°
â”‚   â”œâ”€â”€ secom_labels.data      # SECOM ë¼ë²¨
â”‚   â””â”€â”€ secom.names            # ë°ì´í„°ì…‹ ì„¤ëª…
â”œâ”€â”€ notebooks/                  # Jupyter ë…¸íŠ¸ë¶
â”‚   â”œâ”€â”€ 1-Logistic_Regression_SECOM.ipynb
â”‚   â”œâ”€â”€ 2-NaiveBayes_Text.ipynb
â”‚   â”œâ”€â”€ 3-KNN_Classic.ipynb
â”‚   â””â”€â”€ 4-SVM_SECOM.ipynb
â”œâ”€â”€ requirements.txt           # Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ environment.yml            # Conda í™˜ê²½ íŒŒì¼
â””â”€â”€ README.md                  # ì´ íŒŒì¼
```

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

### 1ï¸âƒ£ Logistic Regression (60ë¶„) - **SECOM ë°ì´í„°**
- ì‹¤ì œ ë°˜ë„ì²´ ì œì¡° ê³µì • ë°ì´í„° ë¶„ì„
- ê³ ì°¨ì› ë°ì´í„° ì „ì²˜ë¦¬ (ê²°ì¸¡ì¹˜, Feature Selection)
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (`class_weight='balanced'`)
- Feature Importance ë¶„ì„

### 2ï¸âƒ£ Naive Bayes (45ë¶„) - **20 Newsgroups í…ìŠ¤íŠ¸**
- í…ìŠ¤íŠ¸ ë°ì´í„° Vectorization (CountVectorizer, TF-IDF)
- Multinomial vs Bernoulli Naive Bayes
- ë…ë¦½ì„± ê°€ì •ì˜ ì‹¤ìš©ì„±
- í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‘ìš© (ìŠ¤íŒ¸ í•„í„°, ê°ì • ë¶„ì„)

### 3ï¸âƒ£ K-Nearest Neighbors (45ë¶„) - **Iris + Wine**
- KNN ì‘ë™ ì›ë¦¬ (ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜)
- k ê°’ ì„ íƒì˜ ì¤‘ìš”ì„±
- Feature Scaling í•„ìˆ˜ì„±
- ì°¨ì›ì˜ ì €ì£¼ (Curse of Dimensionality)

### 4ï¸âƒ£ Support Vector Machine (60ë¶„) - **SECOM ë°ì´í„°**
- Linear vs RBF Kernel ë¹„êµ
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (C, gamma)
- ê³ ì°¨ì› ë°ì´í„°ì—ì„œì˜ SVM ê°•ì 
- Logistic Regressionê³¼ ì„±ëŠ¥ ë¹„êµ

---

## ğŸš€ í™˜ê²½ ì„¤ì •

### ë°©ë²• 1: Conda í™˜ê²½ ì‚¬ìš© (ê¶Œì¥)

```bash
# í™˜ê²½ ìƒì„±
conda env create -f environment.yml

# í™˜ê²½ í™œì„±í™”
conda activate day8-ml

# Jupyter Notebook ì‹¤í–‰
jupyter notebook
```

### ë°©ë²• 2: pip ì‚¬ìš©

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒì‚¬í•­)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# Jupyter Notebook ì‹¤í–‰
jupyter notebook
```

---

## ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´

### SECOM (SEmiCOnductor Manufacturing)
- **ì¶œì²˜**: UCI Machine Learning Repository
- **ìƒ˜í”Œ**: 1,567ê°œ
- **íŠ¹ì„±**: 590ê°œ (ì„¼ì„œ ì¸¡ì •ê°’)
- **ë¬¸ì œ**: ë¶ˆëŸ‰í’ˆ ì˜ˆì¸¡ (Pass/Fail)
- **í´ë˜ìŠ¤ ë¶ˆê· í˜•**: Pass 93.4% vs Fail 6.6%
- **íŠ¹ì§•**: ê²°ì¸¡ì¹˜ ë§ìŒ, ì‹¤ì œ ì œì¡° ê³µì • ë°ì´í„°
- **ì‚¬ìš©**: Logistic Regression, SVM

### 20 Newsgroups
- **ì¶œì²˜**: scikit-learn built-in dataset
- **ìƒ˜í”Œ**: ~2,800ê°œ (4ê°œ ì¹´í…Œê³ ë¦¬ ì„ íƒ)
- **íŠ¹ì„±**: í…ìŠ¤íŠ¸ (ê°€ë³€ ê¸¸ì´)
- **ë¬¸ì œ**: ë‰´ìŠ¤ ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
- **ì‚¬ìš©**: Naive Bayes

### Iris & Wine
- **ì¶œì²˜**: scikit-learn built-in datasets
- **íŠ¹ì„±**: ì €ì°¨ì› (4-13ê°œ)
- **ë¬¸ì œ**: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜
- **ì‚¬ìš©**: KNN

---

## ğŸ”§ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ

- **Python**: 3.9+
- **NumPy**: ë°°ì—´ ì—°ì‚°
- **Pandas**: ë°ì´í„° ì²˜ë¦¬
- **Scikit-learn**: ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜
- **Matplotlib & Seaborn**: ì‹œê°í™”

---

## ğŸ“ ì‹¤ìŠµ ìˆœì„œ

1. **í™˜ê²½ ì„¤ì • í™•ì¸**
   ```bash
   conda activate day8-ml
   jupyter notebook
   ```

2. **ë…¸íŠ¸ë¶ ì‹¤í–‰ ìˆœì„œ**
   - `1-Logistic_Regression_SECOM.ipynb` â†’ SECOM ë°ì´í„° ì´í•´
   - `2-NaiveBayes_Text.ipynb` â†’ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ê¸°ì´ˆ
   - `3-KNN_Classic.ipynb` â†’ ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜
   - `4-SVM_SECOM.ipynb` â†’ SECOM ì¬ë°©ë¬¸ (ë¹„êµ)

3. **ê° ë…¸íŠ¸ë¶ì˜ ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰**

---

## ğŸ’¡ í•™ìŠµ í¬ì¸íŠ¸

### ë°ì´í„° ì „ì²˜ë¦¬
- **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**: Imputation (í‰ê· ê°’, ì¤‘ì•™ê°’)
- **Feature Selection**: ê²°ì¸¡ì¹˜ ë¹„ìœ¨ë¡œ í•„í„°ë§
- **Scaling**: StandardScaler (KNN, SVM í•„ìˆ˜)
- **Vectorization**: CountVectorizer, TF-IDF (í…ìŠ¤íŠ¸)

### í´ë˜ìŠ¤ ë¶ˆê· í˜•
- **ë¬¸ì œ**: ì†Œìˆ˜ í´ë˜ìŠ¤ ë¬´ì‹œ
- **í•´ê²°ì±…**: `class_weight='balanced'`, SMOTE
- **í‰ê°€**: Accuracy ëŒ€ì‹  F1-score, Precision, Recall

### í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- **GridSearchCV**: ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰
- **Cross-Validation**: ê³¼ì í•© ë°©ì§€
- **Early Stopping**: ë¶ˆí•„ìš”í•œ ê³„ì‚° ë°©ì§€

---

## ğŸ“ ì‹¤ë¬´ ì ìš© ì‚¬ë¡€

### Logistic Regression + SECOM
- ë°˜ë„ì²´ ë¶ˆëŸ‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
- ì¤‘ìš” ì„¼ì„œ ì‹ë³„ë¡œ ëª¨ë‹ˆí„°ë§ ë¹„ìš© ì ˆê°

### Naive Bayes + í…ìŠ¤íŠ¸
- ì´ë©”ì¼ ìŠ¤íŒ¸ í•„í„°
- ê³ ê° ë¦¬ë·° ê°ì • ë¶„ì„
- ë¬¸ì„œ ìë™ ë¶„ë¥˜

### KNN
- ì¶”ì²œ ì‹œìŠ¤í…œ (ìœ ì‚¬ ì‚¬ìš©ì ì°¾ê¸°)
- ì´ìƒ íƒì§€ (Local Outlier Factor)

### SVM
- ì´ë¯¸ì§€ ë¶„ë¥˜ (Feature Extraction í›„)
- ì˜ë£Œ ì§„ë‹¨ (ê³ ì°¨ì› íŠ¹ì„±)

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë©”ëª¨ë¦¬**: SECOM ë°ì´í„° ë¡œë”© ì‹œ ~50MB RAM í•„ìš”
2. **ì‹¤í–‰ ì‹œê°„**: GridSearchCV ì‚¬ìš© ì‹œ 5-10ë¶„ ì†Œìš” ê°€ëŠ¥
3. **Jupyter Kernel**: ë…¸íŠ¸ë¶ ì‹¤í–‰ ì „ `day8-ml` ì»¤ë„ ì„ íƒ í™•ì¸
4. **ë°ì´í„° ê²½ë¡œ**: ë…¸íŠ¸ë¶ì€ `../data/` ê²½ë¡œ ê°€ì •

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [UCI SECOM Dataset](https://archive.ics.uci.edu/ml/datasets/SECOM)
- [20 Newsgroups Dataset](http://qwone.com/~jason/20Newsgroups/)

---

## ğŸ¤ ë¬¸ì˜ ë° í”¼ë“œë°±

ì‹¤ìŠµ ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. ë¨¼ì € ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
2. í™˜ê²½ ì„¤ì • ì¬í™•ì¸ (`conda list`)
3. ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸ (`ls data/`)

---

**Happy Learning! ğŸš€**
